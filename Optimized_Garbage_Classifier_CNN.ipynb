{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tm3OnUjWTpL",
        "outputId": "96df1d46-3277-4958-8337-ec6803c94a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path to your dataset directory\n",
        "dataset_dir = '/content/drive/MyDrive/TrashNet'\n",
        "\n",
        "# Check if the directory exists\n",
        "if os.path.exists(dataset_dir):\n",
        "    print(\"Dataset directory exists.\")\n",
        "else:\n",
        "    print(\"Dataset directory does not exist.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp2rH5MvWZ5w",
        "outputId": "b5c729a0-b6cf-4e21-b340-b8515e371ffb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset directory exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # For numerical computations\n",
        "import pandas as pd # For dataframe operations\n",
        "\n",
        "# Importing Matplotlib and seaborn for Data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# For mathematical calculations\n",
        "import math\n",
        "\n",
        "# All tensorflow utilities for creating, training and working with a CNN.\n",
        "import tensorflow as tf # (version 2.8.4)\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout,BatchNormalization\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# For evaluation matrices for comparative analysis\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, auc, classification_report, confusion_matrix\n"
      ],
      "metadata": {
        "id": "3AKEvP5CWlWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Define the path to the dataset\n",
        "dataset_dir = '/content/drive/MyDrive/TrashNet'\n",
        "\n",
        "# Categories in the dataset\n",
        "categories = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "\n",
        "# Load images and labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for category in categories:\n",
        "    path = os.path.join(dataset_dir, category)\n",
        "    class_num = categories.index(category)\n",
        "    if not os.path.isdir(path):\n",
        "        print(f\"Directory {path} not found.\")\n",
        "        continue\n",
        "    for img in os.listdir(path):\n",
        "        img_path = os.path.join(path, img)\n",
        "        try:\n",
        "            img_array = cv2.imread(img_path)\n",
        "            if img_array is not None:\n",
        "                img_array = cv2.resize(img_array, (128, 128))\n",
        "                data.append(img_array)\n",
        "                labels.append(class_num)\n",
        "            else:\n",
        "                print(f\"Failed to load image {img_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")\n",
        "\n",
        "# Convert to numpy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Check if data is loaded correctly\n",
        "print(f\"Loaded {len(data)} images.\")\n",
        "\n",
        "# Ensure there is data to split\n",
        "if len(data) == 0:\n",
        "    raise ValueError(\"No images loaded. Check dataset path and structure.\")\n",
        "\n",
        "# Normalize data\n",
        "data = data / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "labels = to_categorical(labels, num_classes=len(categories))\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check if split was successful\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Testing set size: {len(X_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7LJW0wCW1Yf",
        "outputId": "92cfbcdd-a979-48c1-f465-41f2215aa703"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1930 images.\n",
            "Training set size: 1544\n",
            "Testing set size: 386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple CNN Model"
      ],
      "metadata": {
        "id": "fVxnYpV6HNJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_cnn():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(len(categories), activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model_simple = simple_cnn()\n",
        "model_simple.summary()\n",
        "model_simple.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "7jybLTOvXOLj",
        "outputId": "8923f90e-04e8-41e1-8482-8e7489af585f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Sequential' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-65ec046e9650>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel_simple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel_simple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel_simple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-65ec046e9650>\u001b[0m in \u001b[0;36msimple_cnn\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msimple_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     model = Sequential([\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deeper CNN Model"
      ],
      "metadata": {
        "id": "9DZlhEULHRRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def deeper_cnn():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(len(categories), activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model_deeper = deeper_cnn()\n",
        "model_deeper.summary()\n",
        "model_deeper.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUcQ1i_3mqE9",
        "outputId": "da0525d0-b355-4a59-9bb5-0ac43187d45f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 63, 63, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               6422784   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6517574 (24.86 MB)\n",
            "Trainable params: 6517574 (24.86 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "49/49 [==============================] - 62s 1s/step - loss: 1.4937 - accuracy: 0.3465 - val_loss: 1.5606 - val_accuracy: 0.3031\n",
            "Epoch 2/20\n",
            "49/49 [==============================] - 57s 1s/step - loss: 1.2795 - accuracy: 0.4365 - val_loss: 1.2584 - val_accuracy: 0.4456\n",
            "Epoch 3/20\n",
            "49/49 [==============================] - 57s 1s/step - loss: 1.1274 - accuracy: 0.5330 - val_loss: 1.2594 - val_accuracy: 0.4896\n",
            "Epoch 4/20\n",
            "49/49 [==============================] - 56s 1s/step - loss: 0.9908 - accuracy: 0.6004 - val_loss: 1.5274 - val_accuracy: 0.4352\n",
            "Epoch 5/20\n",
            "49/49 [==============================] - 57s 1s/step - loss: 0.9495 - accuracy: 0.6153 - val_loss: 1.3547 - val_accuracy: 0.4819\n",
            "Epoch 6/20\n",
            "49/49 [==============================] - 56s 1s/step - loss: 0.7240 - accuracy: 0.7189 - val_loss: 1.3208 - val_accuracy: 0.5104\n",
            "Epoch 7/20\n",
            "49/49 [==============================] - 60s 1s/step - loss: 0.5148 - accuracy: 0.8031 - val_loss: 1.4330 - val_accuracy: 0.5389\n",
            "Epoch 8/20\n",
            "49/49 [==============================] - 57s 1s/step - loss: 0.3482 - accuracy: 0.8756 - val_loss: 1.5907 - val_accuracy: 0.5389\n",
            "Epoch 9/20\n",
            "49/49 [==============================] - 56s 1s/step - loss: 0.2754 - accuracy: 0.9087 - val_loss: 1.6848 - val_accuracy: 0.5440\n",
            "Epoch 10/20\n",
            "49/49 [==============================] - 56s 1s/step - loss: 0.1963 - accuracy: 0.9275 - val_loss: 2.4858 - val_accuracy: 0.4870\n",
            "Epoch 11/20\n",
            "49/49 [==============================] - 56s 1s/step - loss: 0.2198 - accuracy: 0.9255 - val_loss: 2.0592 - val_accuracy: 0.5285\n",
            "Epoch 12/20\n",
            "49/49 [==============================] - 56s 1s/step - loss: 0.1838 - accuracy: 0.9339 - val_loss: 2.4244 - val_accuracy: 0.5751\n",
            "Epoch 13/20\n",
            "49/49 [==============================] - 56s 1s/step - loss: 0.0730 - accuracy: 0.9741 - val_loss: 2.4491 - val_accuracy: 0.5518\n",
            "Epoch 14/20\n",
            "49/49 [==============================] - 56s 1s/step - loss: 0.0525 - accuracy: 0.9838 - val_loss: 2.7723 - val_accuracy: 0.5777\n",
            "Epoch 15/20\n",
            "49/49 [==============================] - 54s 1s/step - loss: 0.0349 - accuracy: 0.9916 - val_loss: 2.8972 - val_accuracy: 0.5596\n",
            "Epoch 16/20\n",
            "49/49 [==============================] - 57s 1s/step - loss: 0.0400 - accuracy: 0.9896 - val_loss: 3.2183 - val_accuracy: 0.5155\n",
            "Epoch 17/20\n",
            "49/49 [==============================] - 54s 1s/step - loss: 0.0405 - accuracy: 0.9864 - val_loss: 3.0348 - val_accuracy: 0.5699\n",
            "Epoch 18/20\n",
            "49/49 [==============================] - 63s 1s/step - loss: 0.0209 - accuracy: 0.9961 - val_loss: 3.2610 - val_accuracy: 0.5725\n",
            "Epoch 19/20\n",
            "49/49 [==============================] - 56s 1s/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 3.4803 - val_accuracy: 0.5933\n",
            "Epoch 20/20\n",
            "49/49 [==============================] - 54s 1s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.4797 - val_accuracy: 0.6062\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7873849aaf80>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmmented CNN Model"
      ],
      "metadata": {
        "id": "oLdmDiW0HU-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "def cnn_with_augmentation():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(len(categories), activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model_augmented = cnn_with_augmentation()\n",
        "model_augmented.summary()\n",
        "model_augmented.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=30, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgwvHt5SoHJD",
        "outputId": "7568e93b-a161-4b17-b3f9-8ebf3520c7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 63, 63, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 30, 30, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 14, 14, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               6422784   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6517574 (24.86 MB)\n",
            "Trainable params: 6517574 (24.86 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "49/49 [==============================] - 65s 1s/step - loss: 1.4980 - accuracy: 0.3549 - val_loss: 1.4347 - val_accuracy: 0.3057\n",
            "Epoch 2/30\n",
            "49/49 [==============================] - 62s 1s/step - loss: 1.3495 - accuracy: 0.4171 - val_loss: 1.2849 - val_accuracy: 0.3964\n",
            "Epoch 3/30\n",
            "49/49 [==============================] - 62s 1s/step - loss: 1.3171 - accuracy: 0.4242 - val_loss: 1.2692 - val_accuracy: 0.4352\n",
            "Epoch 4/30\n",
            "49/49 [==============================] - 64s 1s/step - loss: 1.2557 - accuracy: 0.4715 - val_loss: 1.2377 - val_accuracy: 0.5104\n",
            "Epoch 5/30\n",
            "49/49 [==============================] - 63s 1s/step - loss: 1.1877 - accuracy: 0.5110 - val_loss: 1.1676 - val_accuracy: 0.5518\n",
            "Epoch 6/30\n",
            "49/49 [==============================] - 63s 1s/step - loss: 1.1841 - accuracy: 0.5123 - val_loss: 1.3007 - val_accuracy: 0.4223\n",
            "Epoch 7/30\n",
            "49/49 [==============================] - 62s 1s/step - loss: 1.1280 - accuracy: 0.5356 - val_loss: 1.0665 - val_accuracy: 0.5907\n",
            "Epoch 8/30\n",
            "49/49 [==============================] - 62s 1s/step - loss: 1.0873 - accuracy: 0.5654 - val_loss: 1.1087 - val_accuracy: 0.5777\n",
            "Epoch 9/30\n",
            "49/49 [==============================] - 74s 2s/step - loss: 1.0018 - accuracy: 0.6030 - val_loss: 0.9792 - val_accuracy: 0.6295\n",
            "Epoch 10/30\n",
            "49/49 [==============================] - 91s 2s/step - loss: 1.0353 - accuracy: 0.5907 - val_loss: 1.1703 - val_accuracy: 0.5829\n",
            "Epoch 11/30\n",
            "49/49 [==============================] - 62s 1s/step - loss: 0.9827 - accuracy: 0.5965 - val_loss: 1.0678 - val_accuracy: 0.5907\n",
            "Epoch 12/30\n",
            "49/49 [==============================] - 67s 1s/step - loss: 0.8888 - accuracy: 0.6451 - val_loss: 1.0393 - val_accuracy: 0.6244\n",
            "Epoch 13/30\n",
            "49/49 [==============================] - 64s 1s/step - loss: 0.8923 - accuracy: 0.6438 - val_loss: 0.9318 - val_accuracy: 0.6606\n",
            "Epoch 14/30\n",
            "49/49 [==============================] - 63s 1s/step - loss: 0.9140 - accuracy: 0.6347 - val_loss: 1.0163 - val_accuracy: 0.6088\n",
            "Epoch 15/30\n",
            "49/49 [==============================] - 61s 1s/step - loss: 0.8600 - accuracy: 0.6613 - val_loss: 0.9741 - val_accuracy: 0.6710\n",
            "Epoch 16/30\n",
            "49/49 [==============================] - 61s 1s/step - loss: 0.8385 - accuracy: 0.6736 - val_loss: 0.8960 - val_accuracy: 0.6762\n",
            "Epoch 17/30\n",
            "49/49 [==============================] - 64s 1s/step - loss: 0.8021 - accuracy: 0.6891 - val_loss: 0.9636 - val_accuracy: 0.6606\n",
            "Epoch 18/30\n",
            "49/49 [==============================] - 61s 1s/step - loss: 0.7805 - accuracy: 0.6885 - val_loss: 0.9421 - val_accuracy: 0.6710\n",
            "Epoch 19/30\n",
            "49/49 [==============================] - 62s 1s/step - loss: 0.7441 - accuracy: 0.6988 - val_loss: 0.8807 - val_accuracy: 0.6839\n",
            "Epoch 20/30\n",
            "49/49 [==============================] - 62s 1s/step - loss: 0.7389 - accuracy: 0.7066 - val_loss: 0.8698 - val_accuracy: 0.7073\n",
            "Epoch 21/30\n",
            "49/49 [==============================] - 61s 1s/step - loss: 0.7070 - accuracy: 0.7306 - val_loss: 0.9335 - val_accuracy: 0.6865\n",
            "Epoch 22/30\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.6979 - accuracy: 0.7345"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional layers\n",
        "    model.add(Conv2D(hp.Int('conv_units', min_value=32, max_value=128, step=32), (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Additional convolutional layers\n",
        "    for i in range(hp.Int('num_conv_layers', 1, 3)):\n",
        "        model.add(Conv2D(hp.Int(f'conv_units_{i}', min_value=32, max_value=128, step=32), (3, 3), activation='relu'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Dropout(hp.Float(f'dropout_rate_{i}', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Fully connected layers\n",
        "    for i in range(hp.Int('num_dense_layers', 1, 3)):\n",
        "        model.add(Dense(hp.Int(f'dense_units_{i}', min_value=128, max_value=512, step=128), activation='relu'))\n",
        "        model.add(Dropout(hp.Float(f'dropout_rate_dense_{i}', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(Dense(len(categories), activation='softmax'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop']),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=20,\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='trashnet_tuning'\n",
        ")\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "4t2bWbTyciXU",
        "outputId": "ebfc62d0-3f0c-49d6-99eb-a1daf39b76a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras_tuner'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d2ca1686b8e8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tuner\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_tuner'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras_tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0iNX_MLclsS",
        "outputId": "22a7f721-4ddd-4607-dc13-a9cca80db408"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2024.2.2)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "best_model.summary()\n",
        "best_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "n7qbK_YSdGlq",
        "outputId": "b326226c-c9c6-4145-f0b8-322201a36d97"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'best_hps' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-49da1e0637c6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_hps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'best_hps' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models with Optimal Hyperparameters, Regularization, and Learning Rate Scheduler"
      ],
      "metadata": {
        "id": "TOCdha1mJ0Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# Define learning rate scheduler\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * 0.1\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n"
      ],
      "metadata": {
        "id": "yQs226oMdUid"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional layers with L2 regularization\n",
        "    model.add(Conv2D(hp.Int('conv_units', min_value=32, max_value=128, step=32), (3, 3), activation='relu',\n",
        "                     input_shape=(128, 128, 3), kernel_regularizer=l2(hp.Float('l2_reg', 1e-4, 1e-2, sampling='LOG'))))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Additional convolutional layers with L2 regularization\n",
        "    for i in range(hp.Int('num_conv_layers', 1, 3)):\n",
        "        model.add(Conv2D(hp.Int(f'conv_units_{i}', min_value=32, max_value=128, step=32), (3, 3), activation='relu',\n",
        "                         kernel_regularizer=l2(hp.Float(f'l2_reg_{i}', 1e-4, 1e-2, sampling='LOG'))))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "        model.add(Dropout(hp.Float(f'dropout_rate_{i}', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Fully connected layers with L2 regularization\n",
        "    for i in range(hp.Int('num_dense_layers', 1, 3)):\n",
        "        model.add(Dense(hp.Int(f'dense_units_{i}', min_value=128, max_value=512, step=128), activation='relu',\n",
        "                        kernel_regularizer=l2(hp.Float(f'l2_reg_dense_{i}', 1e-4, 1e-2, sampling='LOG'))))\n",
        "        model.add(Dropout(hp.Float(f'dropout_rate_dense_{i}', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(Dense(len(categories), activation='softmax'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop']),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=1,\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='trashnet_tuning'\n",
        ")\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[lr_scheduler])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TSApZRMdb1R",
        "outputId": "ef929a30-adcc-45fd-ed54-427a3b600690"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 06m 26s]\n",
            "val_accuracy: 0.5984455943107605\n",
            "\n",
            "Best val_accuracy So Far: 0.5984455943107605\n",
            "Total elapsed time: 00h 06m 26s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "best_model.summary()\n",
        "history_best = best_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[lr_scheduler])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEkgJcoWdiH8",
        "outputId": "1a166926-fda7-4784-d774-34e14be70cd1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 63, 63, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 63, 63, 32)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 61, 61, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 30, 30, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 30, 30, 32)        0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 28800)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               3686528   \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3730470 (14.23 MB)\n",
            "Trainable params: 3730470 (14.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "49/49 [==============================] - 37s 714ms/step - loss: 1.7516 - accuracy: 0.3180 - val_loss: 1.7048 - val_accuracy: 0.3472 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "49/49 [==============================] - 35s 707ms/step - loss: 1.5447 - accuracy: 0.3860 - val_loss: 1.5201 - val_accuracy: 0.3601 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "49/49 [==============================] - 35s 710ms/step - loss: 1.4352 - accuracy: 0.4333 - val_loss: 1.4386 - val_accuracy: 0.4715 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "49/49 [==============================] - 47s 976ms/step - loss: 1.3479 - accuracy: 0.4851 - val_loss: 1.3833 - val_accuracy: 0.4845 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "49/49 [==============================] - 44s 894ms/step - loss: 1.3068 - accuracy: 0.5078 - val_loss: 1.2803 - val_accuracy: 0.4845 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "49/49 [==============================] - 35s 711ms/step - loss: 1.2537 - accuracy: 0.5402 - val_loss: 1.4782 - val_accuracy: 0.4430 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "49/49 [==============================] - 35s 709ms/step - loss: 1.1840 - accuracy: 0.5758 - val_loss: 1.2801 - val_accuracy: 0.5596 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "49/49 [==============================] - 37s 767ms/step - loss: 1.1420 - accuracy: 0.5907 - val_loss: 1.2721 - val_accuracy: 0.5699 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "49/49 [==============================] - 34s 700ms/step - loss: 1.0686 - accuracy: 0.6347 - val_loss: 1.3311 - val_accuracy: 0.5285 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "49/49 [==============================] - 35s 712ms/step - loss: 1.0038 - accuracy: 0.6865 - val_loss: 1.2726 - val_accuracy: 0.5803 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "49/49 [==============================] - 34s 699ms/step - loss: 0.8728 - accuracy: 0.7442 - val_loss: 1.1802 - val_accuracy: 0.6269 - lr: 1.0000e-04\n",
            "Epoch 12/20\n",
            "49/49 [==============================] - 36s 743ms/step - loss: 0.8432 - accuracy: 0.7481 - val_loss: 1.1838 - val_accuracy: 0.6295 - lr: 1.0000e-05\n",
            "Epoch 13/20\n",
            "49/49 [==============================] - 33s 676ms/step - loss: 0.8282 - accuracy: 0.7668 - val_loss: 1.1841 - val_accuracy: 0.6269 - lr: 1.0000e-06\n",
            "Epoch 14/20\n",
            "49/49 [==============================] - 33s 671ms/step - loss: 0.8295 - accuracy: 0.7558 - val_loss: 1.1841 - val_accuracy: 0.6269 - lr: 1.0000e-07\n",
            "Epoch 15/20\n",
            "49/49 [==============================] - 34s 691ms/step - loss: 0.8174 - accuracy: 0.7604 - val_loss: 1.1841 - val_accuracy: 0.6269 - lr: 1.0000e-08\n",
            "Epoch 16/20\n",
            "49/49 [==============================] - 33s 679ms/step - loss: 0.8324 - accuracy: 0.7655 - val_loss: 1.1841 - val_accuracy: 0.6269 - lr: 1.0000e-09\n",
            "Epoch 17/20\n",
            "49/49 [==============================] - 33s 682ms/step - loss: 0.8247 - accuracy: 0.7694 - val_loss: 1.1841 - val_accuracy: 0.6269 - lr: 1.0000e-10\n",
            "Epoch 18/20\n",
            "49/49 [==============================] - 34s 703ms/step - loss: 0.8136 - accuracy: 0.7707 - val_loss: 1.1841 - val_accuracy: 0.6269 - lr: 1.0000e-11\n",
            "Epoch 19/20\n",
            "49/49 [==============================] - 36s 732ms/step - loss: 0.8245 - accuracy: 0.7519 - val_loss: 1.1841 - val_accuracy: 0.6269 - lr: 1.0000e-12\n",
            "Epoch 20/20\n",
            "49/49 [==============================] - 34s 702ms/step - loss: 0.8274 - accuracy: 0.7675 - val_loss: 1.1841 - val_accuracy: 0.6269 - lr: 1.0000e-13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and Load the models"
      ],
      "metadata": {
        "id": "VRPKvQ4rbePI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the models\n",
        "model_simple.save('model_simple.h5')\n",
        "model_deeper.save('model_deeper.h5')\n",
        "model_augmented.save('model_augmented.h5')\n",
        "best_model.save('model_optimized.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "6XtVTWCpbZUf",
        "outputId": "4bbb73dd-8467-42a2-ab05-d050968481f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_simple' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6fd64b690cfd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_simple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_simple.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel_deeper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_deeper.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_augmented\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_augmented.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_optimized.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_simple' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the models\n",
        "model_simple = load_model('model_simple.h5')\n",
        "model_deeper = load_model('model_deeper.h5')\n",
        "model_augmented = load_model('model_augmented.h5')\n",
        "model_optimized = load_model('model_optimized.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "LxrqoL3ybdYm",
        "outputId": "679f51a9-47b3-4db9-9422-b6ebbcdab885"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "No file or directory found at model_simple.h5",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ac45940ade88>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_simple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_simple.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel_deeper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_deeper.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel_augmented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_augmented.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    235\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             )\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at model_simple.h5"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison & Evaluation"
      ],
      "metadata": {
        "id": "RilDH_rGR0Fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate and get metrics\n",
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    # Get predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "    f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
        "\n",
        "    # Calculate specificity for each class\n",
        "    cm = confusion_matrix(y_true, y_pred_classes)\n",
        "    specificity = np.mean([cm[i,i]/(cm[i,i] + np.sum(cm[i,:])-cm[i,i]) for i in range(cm.shape[0])])\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_true, y_pred_classes, target_names=categories)\n",
        "\n",
        "    # AUC-ROC\n",
        "    y_test_bin = to_categorical(y_true, num_classes=len(categories))\n",
        "    auc_roc = roc_auc_score(y_test_bin, y_pred, multi_class='ovr')\n",
        "\n",
        "    print(f\"{model_name} Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall (Sensitivity): {recall}\")\n",
        "    print(f\"Specificity: {specificity}\")\n",
        "    print(f\"AUC-ROC: {auc_roc}\")\n",
        "    print(f\"Classification Report:\\n{class_report}\")\n",
        "\n",
        "    return accuracy, f1, precision, recall, specificity, auc_roc, y_true, y_pred\n",
        "\n",
        "# Assuming your models are named model_simple, model_deeper, model_augmented, and model_optimized\n",
        "metrics_simple = evaluate_model(model_simple, X_test, y_test, \"Simple CNN\")\n",
        "metrics_deeper = evaluate_model(model_deeper, X_test, y_test, \"Deeper CNN\")\n",
        "metrics_augmented = evaluate_model(model_augmented, X_test, y_test, \"Data Augmented CNN\")\n",
        "metrics_optimized = evaluate_model(model_optimized, X_test, y_test, \"Optimized CNN\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "vzdYFuF-R3ew",
        "outputId": "2d7a4350-101b-4114-8bd0-35c366d18018"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 2s 119ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Number of classes, 5, does not match size of target_names, 6. Try specifying the labels parameter",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f8e6170b7396>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Assuming your models are named model_simple, model_deeper, model_augmented, and model_optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mmetrics_simple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_simple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Simple CNN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mmetrics_deeper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_deeper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Deeper CNN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mmetrics_augmented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_augmented\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Data Augmented CNN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-f8e6170b7396>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, X_test, y_test, model_name)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Classification report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mclass_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# AUC-ROC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2330\u001b[0m             )\n\u001b[1;32m   2331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2333\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of classes, 5, does not match size of target_names, 6. Try specifying the labels parameter"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot ROC curves\n",
        "def plot_roc_curve(y_true, y_pred, model_name):\n",
        "    fpr = {}\n",
        "    tpr = {}\n",
        "    roc_auc = {}\n",
        "\n",
        "    for i in range(len(categories)):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Compute micro-average ROC curve and ROC area\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    plt.figure()\n",
        "    lw = 2\n",
        "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='darkorange',\n",
        "             lw=lw, label='Micro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"micro\"]))\n",
        "\n",
        "    for i in range(len(categories)):\n",
        "        plt.plot(fpr[i], tpr[i], lw=lw, label='ROC curve of class {0} (area = {1:0.2f})'.format(categories[i], roc_auc[i]))\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'Receiver Operating Characteristic for {model_name}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot ROC curves for each model\n",
        "plot_roc_curve(metrics_simple[6], metrics_simple[7], \"Simple CNN\")\n",
        "plot_roc_curve(metrics_deeper[6], metrics_deeper[7], \"Deeper CNN\")\n",
        "plot_roc_curve(metrics_augmented[6], metrics_augmented[7], \"Data Augmented CNN\")\n",
        "plot_roc_curve(metrics_optimized[6], metrics_optimized[7], \"Optimized CNN\")\n"
      ],
      "metadata": {
        "id": "RZC0sAxESHM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Compile metrics into a DataFrame\n",
        "metrics_df = pd.DataFrame({\n",
        "    \"Model\": [\"Simple CNN\", \"Deeper CNN\", \"Data Augmented CNN\", \"Optimized CNN\"],\n",
        "    \"Accuracy\": [metrics_simple[0], metrics_deeper[0], metrics_augmented[0], metrics_optimized[0]],\n",
        "    \"F1 Score\": [metrics_simple[1], metrics_deeper[1], metrics_augmented[1], metrics_optimized[1]],\n",
        "    \"Precision\": [metrics_simple[2], metrics_deeper[2], metrics_augmented[2], metrics_optimized[2]],\n",
        "    \"Recall (Sensitivity)\": [metrics_simple[3], metrics_deeper[3], metrics_augmented[3], metrics_optimized[3]],\n",
        "    \"Specificity\": [metrics_simple[4], metrics_deeper[4], metrics_augmented[4], metrics_optimized[4]],\n",
        "    \"AUC-ROC\": [metrics_simple[5], metrics_deeper[5], metrics_augmented[5], metrics_optimized[5]]\n",
        "})\n",
        "\n",
        "print(metrics_df)\n"
      ],
      "metadata": {
        "id": "rcdKGU1RSMNk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}